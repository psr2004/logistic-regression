{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Theoretical Questions**"
      ],
      "metadata": {
        "id": "Yri91l0I-92K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "* Logistic Regression is used for classification problems where the output is categorical (e.g., yes/no, 0/1), unlike Linear Regression which is used for predicting continuous values.\n",
        "\n",
        "2. What is the mathematical equation of Logistic Regression?\n",
        "* The equation is: P(y=1|X) = 1 / (1 + e^-(β0 + β1X1 + β2X2 + ... + βnXn))\n",
        "\n",
        "3. Why do we use the Sigmoid function in Logistic Regression?\n",
        "* The Sigmoid function maps any real-valued number to a value between 0 and 1, making it ideal for modeling probabilities in classification tasks.\n",
        "\n",
        "4. What is the cost function of Logistic Regression?\n",
        "* It uses the log loss or binary cross-entropy function, which penalizes incorrect predictions more heavily the more confident they are.\n",
        "\n",
        "5. What is Regularization in Logistic Regression? Why is it needed?\n",
        "* Regularization adds a penalty to the loss function to prevent overfitting by discouraging large coefficients.\n",
        "\n",
        "6. Explain the difference between Lasso, Ridge, and Elastic Net regression.\n",
        "* Lasso (L1) shrinks some coefficients to zero (feature selection), Ridge (L2) penalizes the square of coefficients, and Elastic Net combines both L1 and L2 penalties.\n",
        "\n",
        "7. When should we use Elastic Net instead of Lasso or Ridge?\n",
        "* When there are multiple features that are correlated with each other, Elastic Net performs better than either Lasso or Ridge alone.\n",
        "\n",
        "8. What is the impact of the regularization parameter (λ) in Logistic Regression?\n",
        "* A higher λ increases the regularization effect, shrinking coefficients more and potentially underfitting. A lower λ reduces regularization, possibly leading to overfitting.\n",
        "\n",
        "9. What are the key assumptions of Logistic Regression?\n",
        "* Assumptions include: the dependent variable is binary, no multicollinearity among independent variables, and a linear relationship between independent variables and the log odds.\n",
        "\n",
        "10. What are some alternatives to Logistic Regression for classification tasks?\n",
        "* Alternatives include Decision Trees, Random Forest, Support Vector Machines (SVM), Naive Bayes, and Neural Networks.\n",
        "\n",
        "11. What are Classification Evaluation Metrics?\n",
        "* Accuracy, Precision, Recall, F1-Score, ROC-AUC, and Confusion Matrix are common metrics used to evaluate classification models.\n",
        "\n",
        "12. How does class imbalance affect Logistic Regression?\n",
        "* Class imbalance can lead to biased predictions toward the majority class, reducing the model’s ability to identify the minority class correctly.\n",
        "\n",
        "13. What is Hyperparameter Tuning in Logistic Regression?\n",
        "* It involves optimizing parameters such as the regularization strength (C), solver, and penalty type to improve model performance.\n",
        "\n",
        "14. What are different solvers in Logistic Regression? Which one should be used?\n",
        "* Solvers include 'liblinear', 'saga', 'lbfgs', 'newton-cg', and 'sag'. Choice depends on dataset size, sparsity, and whether L1 or L2 regularization is used.\n",
        "\n",
        "15. How is Logistic Regression extended for multiclass classification?\n",
        "* Using strategies like One-vs-Rest (OvR) or multinomial (Softmax) Logistic Regression to handle more than two classes.\n",
        "\n",
        "16. What are the advantages and disadvantages of Logistic Regression?\n",
        "* Advantages: simple, interpretable, fast. Disadvantages: assumes linear decision boundary, not good with complex patterns or non-linearly separable data.\n",
        "\n",
        "17. What are some use cases of Logistic Regression?\n",
        "* Spam detection, disease prediction, credit scoring, churn prediction, and image classification (binary).\n",
        "\n",
        "18. What is the difference between Softmax Regression and Logistic Regression?\n",
        "* Softmax regression generalizes logistic regression to multiclass classification by computing probabilities for each class and ensuring they sum to 1.\n",
        "\n",
        "19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
        "* OvR is simpler and works well for imbalanced classes; Softmax is more precise when classes are balanced and interrelated.\n",
        "\n",
        "20. How do we interpret coefficients in Logistic Regression?\n",
        "* The coefficients indicate the change in log odds for a unit change in the predictor. Exponentiating them gives the odds ratio.\n"
      ],
      "metadata": {
        "id": "JJBPxbZR-9vN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Practical Problem**"
      ],
      "metadata": {
        "id": "-_Skf7tp-9hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  # 1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv8trJIrVy2s",
        "outputId": "bde19f34-7d4e-4871-8761-de6b0e9df2f7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.956140350877193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"L1 Regularization Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFkKevFQVy7F",
        "outputId": "edcd5b2f-99d8-4714-dc2c-47881beec5be"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 Regularization Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"L2 Regularization Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Coefficients:\", model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ol4gb-yVy9e",
        "outputId": "bb589358-a3d5-487e-8705-2781fe1d9ced"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 Regularization Accuracy: 0.956140350877193\n",
            "Coefficients: [[ 2.13248406e+00  1.52771940e-01 -1.45091255e-01 -8.28669349e-04\n",
            "  -1.42636015e-01 -4.15568847e-01 -6.51940282e-01 -3.44456106e-01\n",
            "  -2.07613380e-01 -2.97739324e-02 -5.00338038e-02  1.44298427e+00\n",
            "  -3.03857384e-01 -7.25692126e-02 -1.61591524e-02 -1.90655332e-03\n",
            "  -4.48855442e-02 -3.77188737e-02 -4.17516190e-02  5.61347410e-03\n",
            "   1.23214996e+00 -4.04581097e-01 -3.62091502e-02 -2.70867580e-02\n",
            "  -2.62630530e-01 -1.20898539e+00 -1.61796947e+00 -6.15250835e-01\n",
            "  -7.42763610e-01 -1.16960181e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Elastic Net Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TctyJa_8VzAL",
        "outputId": "231dcb7f-96e8-4c07-ca3e-d9fce86dfdf6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elastic Net Accuracy: 0.9649122807017544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Multiclass Classification Accuracy (OvR):\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fiy-LHpkVzCk",
        "outputId": "760b84f8-f967-49bb-f103-bd7bef2e05b1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Classification Accuracy (OvR): 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1.0, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Accuracy:\", grid.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuoQS-BSVzE-",
        "outputId": "a5ab7768-b57c-4e12-e098-a970213b3a47"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Accuracy: 0.9583333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "scores = cross_val_score(model, X, y, cv=skf)\n",
        "\n",
        "print(\"Cross-Validated Accuracy Scores:\", scores)\n",
        "print(\"Average Accuracy:\", scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIspkOocVzHe",
        "outputId": "a7f13161-a95c-4728-ebf8-b0c16c1c69f5"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validated Accuracy Scores: [0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
            "Average Accuracy: 0.9733333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "df = pd.read_csv('sample_data.csv')\n",
        "df = df.drop(['S', 'Product', 'Category', 'Region', 'Month', 'Day_of_Week'], axis=1)\n",
        "df = df.dropna()\n",
        "X = df.drop('Returns', axis=1)\n",
        "y = df['Returns']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"CSV Dataset Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzx5BRj4VzJ3",
        "outputId": "cfdcefcd-c7cd-45de-85b8-e5db2f676e00"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV Dataset Accuracy: 0.9523809523809523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'solver': ['saga', 'liblinear', 'lbfgs']\n",
        "}\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=5, cv=3)\n",
        "search.fit(X_train, y_train)\n",
        "print(\"Best Params:\", search.best_params_)\n",
        "print(\"Accuracy:\", search.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FShT9KRYev_",
        "outputId": "bf766344-fe3f-4107-8bf8-7a74dcfd7007"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'solver': 'saga', 'penalty': 'l1', 'C': 1}\n",
            "Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "6 fits failed out of a total of 15.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1203, in fit\n",
            "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
            "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 63, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.96190476 0.8        0.93333333        nan        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10.  Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "ovo_model = OneVsOneClassifier(LogisticRegression())\n",
        "ovo_model.fit(X_train, y_train)\n",
        "print(\"OvO Accuracy:\", ovo_model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAYtDIiSY3j6",
        "outputId": "8ed934c7-fadc-46fe-d3e2-08eb7b3c666b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OvO Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification.\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "X_bin, y_bin = X[y != 2], y[y != 2]\n",
        "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(X_bin, y_bin, test_size=0.3, random_state=42)\n",
        "\n",
        "model_bin = LogisticRegression()\n",
        "model_bin.fit(X_train_bin, y_train_bin)\n",
        "y_pred_bin = model_bin.predict(X_test_bin)\n",
        "\n",
        "cm = confusion_matrix(y_test_bin, y_pred_bin)\n",
        "ConfusionMatrixDisplay(cm).plot()\n",
        "print(\"Confusion Matrix shown.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "2isDNQhpY4Od",
        "outputId": "8ed7b36e-74f2-4750-af1c-2791d04f71d3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix shown.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score.\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_bin, y_pred_bin))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3yqQECJY9TH",
        "outputId": "963a49e7-c547-44f8-f8a2-7a260d44c10b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        17\n",
            "           1       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance.\n",
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
        "weights = dict(zip(np.unique(y), class_weights))\n",
        "\n",
        "imbalanced_model = LogisticRegression(class_weight=weights)\n",
        "imbalanced_model.fit(X_train, y_train)\n",
        "print(\"Accuracy with class weights:\", imbalanced_model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-HyJHZ2Y-RM",
        "outputId": "efe04292-4e48-4f41-a374-eaf840c38fcb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with class weights: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance.\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
        "df = df[['Age', 'Fare', 'Survived']].dropna()\n",
        "X = df[['Age', 'Fare']]\n",
        "y = df['Survived']\n",
        "\n",
        "imp = SimpleImputer(strategy='mean')\n",
        "X = imp.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Titanic Accuracy:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag1Znvr0Y-7s",
        "outputId": "bd5554c2-fde6-4c67-8fc2-982fe325e312"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Titanic Accuracy: 0.6312849162011173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scalingM\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=0)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Accuracy after scaling:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD18DIkbY_iR",
        "outputId": "e24855f7-2ade-4ec4-8645-0a7a72c67074"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after scaling: 0.6312849162011173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "model_bin.fit(X_train_bin, y_train_bin)\n",
        "y_probs = model_bin.predict_proba(X_test_bin)[:, 1]\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test_bin, y_probs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAUW6F4rZAJm",
        "outputId": "e4539ba3-f085-4071-9fc8-5828f08f1a0e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy.\n",
        "model = LogisticRegression(C=0.5)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Accuracy with C=0.5:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJvcW0uHZA8A",
        "outputId": "03c67ae4-0153-4e53-cc26-efafa05a0462"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with C=0.5: 0.6312849162011173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 18. Write a Python program to train Logistic Regression and identify important features based on model coefficients.\n",
        "coeffs = model.coef_[0]\n",
        "print(\"Feature importances:\", coeffs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijc-eEBAZBnI",
        "outputId": "22391229-69d6-4250-e39e-1e47288cbb92"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature importances: [-0.28208698  1.04757353]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa Score.\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Cohen’s Kappa Score:\", cohen_kappa_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YABwegVTZCJB",
        "outputId": "89c96851-982b-473d-deb3-f1bf423ba153"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen’s Kappa Score: 0.19545083083628434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification.\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test_bin, y_probs)\n",
        "plt.plot(recall, precision)\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "TIB3LX_1ZC0R",
        "outputId": "50f0a0d3-190f-4d92-df2f-8f0e4b3f99ad"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy\n",
        "solvers = ['liblinear', 'lbfgs', 'saga']\n",
        "for solver in solvers:\n",
        "    try:\n",
        "        model = LogisticRegression(solver=solver, max_iter=1000)\n",
        "        model.fit(X_train, y_train)\n",
        "        print(f\"Solver {solver}, Accuracy: {model.score(X_test, y_test)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Solver {solver} failed:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk3J3MmYZDe-",
        "outputId": "5db59b95-87e0-457f-e398-4034dfc97e9c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solver liblinear, Accuracy: 0.6312849162011173\n",
            "Solver lbfgs, Accuracy: 0.6312849162011173\n",
            "Solver saga, Accuracy: 0.6312849162011173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC)\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "print(\"MCC:\", matthews_corrcoef(y_test_bin, y_pred_bin))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSahM0rrZEHa",
        "outputId": "c07ed841-7f7b-471c-91be-ed7d8526a74c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCC: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling\n",
        "X_train_raw, X_test_raw, _, _ = train_test_split(X, y, random_state=0)\n",
        "\n",
        "model_raw = LogisticRegression()\n",
        "model_raw.fit(X_train_raw, y_train)\n",
        "acc_raw = model_raw.score(X_test_raw, y_test)\n",
        "\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train, y_train)\n",
        "acc_scaled = model_scaled.score(X_test, y_test)\n",
        "\n",
        "print(\"Accuracy Raw:\", acc_raw)\n",
        "print(\"Accuracy Scaled:\", acc_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDNfUUa0ZFHS",
        "outputId": "d389dda0-c79b-48c9-8b43-af2e91d1ee5a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Raw: 0.6312849162011173\n",
            "Accuracy Scaled: 0.6312849162011173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "C_values = [0.01, 0.1, 1, 10]\n",
        "for c in C_values:\n",
        "    model = LogisticRegression(C=c)\n",
        "    scores = cross_val_score(model, X, y, cv=5)\n",
        "    print(f\"C={c}, Mean CV Accuracy: {scores.mean():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSwZ5kOWZGbb",
        "outputId": "4ace9c90-1891-4fb1-ec78-8fb1f8613dd8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=0.01, Mean CV Accuracy: 0.650\n",
            "C=0.1, Mean CV Accuracy: 0.651\n",
            "C=1, Mean CV Accuracy: 0.651\n",
            "C=10, Mean CV Accuracy: 0.651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions\n",
        "import joblib\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "joblib.dump(model, \"log_model.pkl\")\n",
        "\n",
        "loaded_model = joblib.load(\"log_model.pkl\")\n",
        "print(\"Loaded model accuracy:\", loaded_model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vohPwtEOZHJb",
        "outputId": "255bb383-8f6f-4416-a7c2-f4f4bfe54b01"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model accuracy: 0.6312849162011173\n"
          ]
        }
      ]
    }
  ]
}